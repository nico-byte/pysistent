import numpy as np
import torch
import asyncio

from typing import List
from .Models import Models
from .utils import tokenize_text


class Inference(Models):
    """
    Provides a class for running the inference of Whisper speech recognition models.
    --------------------------------------------------------------------------------
    Paramters
    ---------
    model_tpye: str
        The model_type to use. Default: "pretrained"
    model_size: str
        The size of the model to use. Default: "small"
    device: str
        The device to use for PyTorch operations. Default: None
    """
    async def __ainit__(self, model_type: str="pretrained", model_size: str="small", device: str=None):
        super().__init__(model_type, model_size, device)
        
        self.transcript: str = ""
        self.original_tokens: List = []
        self.processed_tokens: List = []
        
    async def run_inference(self, audio_data: np.array):
        """Runs the appropriate inference method based on the configured model type.
    
        If the model type is "vanilla", runs the `run_vanilla` method. \n
        If the model type is "pretrained", runs the `run_pretrained` method. \n
        Finally, calls the `preprocess` method.
    
        Args:
            audio_data (np.array): The audio data to run inference on.
        """
        if self.model_type == "vanilla":
            await self.run_vanilla(audio_data)
            
        elif self.model_type == "pretrained":
            await self.run_pretrained(audio_data)
        
        await self.preprocess()
    
    async def run_vanilla(self, audio_data: np.array):
        """Runs the vanilla speech recognition model on the provided audio data.
    
        Args:
            audio_data (np.array): The audio data to run inference on.
        """
        audio_data_transformed = audio_data.flatten().astype(np.float32) / 32768.0
        transcript = await asyncio.to_thread(self.speech_model.transcribe, audio_data_transformed, language="de")
        
        self.transcript = transcript['text']
    
    async def run_pretrained(self, audio_data: np.array):
        """Runs the pretrained speech recognition model on the provided audio data.
    
        Args:
            audio_data (np.array): The audio data to run inference on.
        """
        audio_data_transformed = audio_data.flatten().astype(np.float32) / 32768.0
        waveform = torch.from_numpy(audio_data_transformed)
        
        inputs = self.processor(waveform, sampling_rate=16000, return_tensors="pt")
        
        input_features = inputs.input_features
        input_features = input_features.to(self.device)
        
        generated_ids = await asyncio.to_thread(self.speech_model.generate, inputs=input_features, max_new_tokens=225)
        transcript = await asyncio.to_thread(self.processor.batch_decode, generated_ids, skip_special_tokens=True)

        self.transcript = transcript[0]
        
    async def preprocess(self):
        """Preprocesses the transcript generated from the speech recognition model.
    
        This method takes the transcript generated by the speech recognition model and performs any necessary preprocessing steps, such as cleaning or normalizing the text.
        """
        self.original_tokens, self.processed_tokens = await asyncio.to_thread(tokenize_text, self.transcript)