<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>pysistent.InputStreamGenerator API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pysistent.InputStreamGenerator</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import sounddevice as sd
import asyncio

from async_class import AsyncClass


class InputStreamGenerator(AsyncClass):
    &#34;&#34;&#34;
    https://github.com/tobiashuttinger/openai-whisper-realtime/blob/main/openai-whisper-realtime.py \n
    Provides a class for generating an input stream of audio data.
    --------------------------------------------------------------
    Parameters
    ----------
    samplerate: int
        The samplerate to use for the input stream.
    blocksize: int
        The size of the blocks to use for the input stream.
    silence_ratio: int
        The max amount of silent values in one block.
    ajustment_time: int
        The duration used for generating the silence_threshold.
    silence_threshold: int
        If it is not desired to auto generate a silence_threshold, set this value to a desired value.
    &#34;&#34;&#34;
    async def __ainit__(self, samplerate: int, blocksize: int, silence_ratio: int, adjustment_time: int, silence_threshold: int):  
        self.SAMPLERATE = samplerate
        self.BLOCKSIZE = blocksize
        self.SILENCE_RATIO = silence_ratio
        self.ADJUSTMENT_TIME = adjustment_time
        self.SILENCE_THRESHOLD = silence_threshold
        
        self.global_ndarray: np.ndarray = None
        self.temp_ndarray: np.ndarray = None

    async def generate(self):
        &#34;&#34;&#34;Generates an input stream of audio data asynchronously.
    
        This method sets up an asynchronous input stream using the `sounddevice` library, with a specified sample rate, block size, and callback function. The callback function puts the incoming audio data and status into an asynchronous queue, which is then yielded one block at a time.
    
        Yields:
            Tuple[numpy.ndarray, int]: A tuple containing the audio data block and the status of the input stream.
        &#34;&#34;&#34;
        q_in = asyncio.Queue()
        loop = asyncio.get_event_loop()

        def callback(in_data, _, __, state):
            loop.call_soon_threadsafe(q_in.put_nowait, (in_data.copy(), state))

        stream = sd.InputStream(samplerate=self.SAMPLERATE, channels=1, dtype=&#39;int16&#39;, blocksize=self.BLOCKSIZE, callback=callback)
        with stream:
            while True:
                indata, status = await q_in.get()
                yield indata, status
    
    async def set_silence_threshold(self):
        &#34;&#34;&#34;Automatically sets the silence threshold for the input stream based on the first few seconds of audio data.
    
        This method processes incoming audio data from the input stream, computes the average loudness over the first few seconds, and sets the `SILENCE_THRESHOLD` attribute based on the computed average loudness and the `SILENCE_RATIO` parameter.
    
        The method continues processing audio data until the `ADJUSTMENT_TIME` duration has elapsed, at which point it sets the `SILENCE_THRESHOLD` and exits.
        &#34;&#34;&#34;
        blocks_processed: int = 0
        loudness_values: list = []

        async for indata, _ in self.generate():
            blocks_processed += 1
            indata_flattened: np.ndarray = abs(indata.flatten())

            # Compute loudness over first few seconds to adjust silence threshold
            loudness_values.append(np.mean(indata_flattened))

            # Stop recording after ADJUSTMENT_TIME seconds
            if blocks_processed &gt;= self.ADJUSTMENT_TIME * self.SAMPLERATE / self.BLOCKSIZE:
                self.SILENCE_THRESHOLD = int((np.mean(loudness_values) * self.SILENCE_RATIO) / 15)
                break
            
        print(f&#39;\nSet SILENCE_THRESHOLD to {self.SILENCE_THRESHOLD}\n&#39;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pysistent.InputStreamGenerator.InputStreamGenerator"><code class="flex name class">
<span>class <span class="ident">InputStreamGenerator</span></span>
<span>(</span><span>*args: Any, **kwargs: Any)</span>
</code></dt>
<dd>
<div class="desc"><p><a href="https://github.com/tobiashuttinger/openai-whisper-realtime/blob/main/openai-whisper-realtime.py">https://github.com/tobiashuttinger/openai-whisper-realtime/blob/main/openai-whisper-realtime.py</a> </p>
<h2 id="provides-a-class-for-generating-an-input-stream-of-audio-data">Provides a class for generating an input stream of audio data.</h2>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>samplerate</code></strong> :&ensp;<code>int</code></dt>
<dd>The samplerate to use for the input stream.</dd>
<dt><strong><code>blocksize</code></strong> :&ensp;<code>int</code></dt>
<dd>The size of the blocks to use for the input stream.</dd>
<dt><strong><code>silence_ratio</code></strong> :&ensp;<code>int</code></dt>
<dd>The max amount of silent values in one block.</dd>
<dt><strong><code>ajustment_time</code></strong> :&ensp;<code>int</code></dt>
<dd>The duration used for generating the silence_threshold.</dd>
<dt><strong><code>silence_threshold</code></strong> :&ensp;<code>int</code></dt>
<dd>If it is not desired to auto generate a silence_threshold, set this value to a desired value.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class InputStreamGenerator(AsyncClass):
    &#34;&#34;&#34;
    https://github.com/tobiashuttinger/openai-whisper-realtime/blob/main/openai-whisper-realtime.py \n
    Provides a class for generating an input stream of audio data.
    --------------------------------------------------------------
    Parameters
    ----------
    samplerate: int
        The samplerate to use for the input stream.
    blocksize: int
        The size of the blocks to use for the input stream.
    silence_ratio: int
        The max amount of silent values in one block.
    ajustment_time: int
        The duration used for generating the silence_threshold.
    silence_threshold: int
        If it is not desired to auto generate a silence_threshold, set this value to a desired value.
    &#34;&#34;&#34;
    async def __ainit__(self, samplerate: int, blocksize: int, silence_ratio: int, adjustment_time: int, silence_threshold: int):  
        self.SAMPLERATE = samplerate
        self.BLOCKSIZE = blocksize
        self.SILENCE_RATIO = silence_ratio
        self.ADJUSTMENT_TIME = adjustment_time
        self.SILENCE_THRESHOLD = silence_threshold
        
        self.global_ndarray: np.ndarray = None
        self.temp_ndarray: np.ndarray = None

    async def generate(self):
        &#34;&#34;&#34;Generates an input stream of audio data asynchronously.
    
        This method sets up an asynchronous input stream using the `sounddevice` library, with a specified sample rate, block size, and callback function. The callback function puts the incoming audio data and status into an asynchronous queue, which is then yielded one block at a time.
    
        Yields:
            Tuple[numpy.ndarray, int]: A tuple containing the audio data block and the status of the input stream.
        &#34;&#34;&#34;
        q_in = asyncio.Queue()
        loop = asyncio.get_event_loop()

        def callback(in_data, _, __, state):
            loop.call_soon_threadsafe(q_in.put_nowait, (in_data.copy(), state))

        stream = sd.InputStream(samplerate=self.SAMPLERATE, channels=1, dtype=&#39;int16&#39;, blocksize=self.BLOCKSIZE, callback=callback)
        with stream:
            while True:
                indata, status = await q_in.get()
                yield indata, status
    
    async def set_silence_threshold(self):
        &#34;&#34;&#34;Automatically sets the silence threshold for the input stream based on the first few seconds of audio data.
    
        This method processes incoming audio data from the input stream, computes the average loudness over the first few seconds, and sets the `SILENCE_THRESHOLD` attribute based on the computed average loudness and the `SILENCE_RATIO` parameter.
    
        The method continues processing audio data until the `ADJUSTMENT_TIME` duration has elapsed, at which point it sets the `SILENCE_THRESHOLD` and exits.
        &#34;&#34;&#34;
        blocks_processed: int = 0
        loudness_values: list = []

        async for indata, _ in self.generate():
            blocks_processed += 1
            indata_flattened: np.ndarray = abs(indata.flatten())

            # Compute loudness over first few seconds to adjust silence threshold
            loudness_values.append(np.mean(indata_flattened))

            # Stop recording after ADJUSTMENT_TIME seconds
            if blocks_processed &gt;= self.ADJUSTMENT_TIME * self.SAMPLERATE / self.BLOCKSIZE:
                self.SILENCE_THRESHOLD = int((np.mean(loudness_values) * self.SILENCE_RATIO) / 15)
                break
            
        print(f&#39;\nSet SILENCE_THRESHOLD to {self.SILENCE_THRESHOLD}\n&#39;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>async_class.AsyncClass</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="pysistent.LiveAudioTranscriber.LiveAudioTranscriber" href="LiveAudioTranscriber.html#pysistent.LiveAudioTranscriber.LiveAudioTranscriber">LiveAudioTranscriber</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pysistent.InputStreamGenerator.InputStreamGenerator.generate"><code class="name flex">
<span>async def <span class="ident">generate</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates an input stream of audio data asynchronously.</p>
<p>This method sets up an asynchronous input stream using the <code>sounddevice</code> library, with a specified sample rate, block size, and callback function. The callback function puts the incoming audio data and status into an asynchronous queue, which is then yielded one block at a time.</p>
<h2 id="yields">Yields</h2>
<dl>
<dt><code>Tuple[numpy.ndarray, int]</code></dt>
<dd>A tuple containing the audio data block and the status of the input stream.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def generate(self):
    &#34;&#34;&#34;Generates an input stream of audio data asynchronously.

    This method sets up an asynchronous input stream using the `sounddevice` library, with a specified sample rate, block size, and callback function. The callback function puts the incoming audio data and status into an asynchronous queue, which is then yielded one block at a time.

    Yields:
        Tuple[numpy.ndarray, int]: A tuple containing the audio data block and the status of the input stream.
    &#34;&#34;&#34;
    q_in = asyncio.Queue()
    loop = asyncio.get_event_loop()

    def callback(in_data, _, __, state):
        loop.call_soon_threadsafe(q_in.put_nowait, (in_data.copy(), state))

    stream = sd.InputStream(samplerate=self.SAMPLERATE, channels=1, dtype=&#39;int16&#39;, blocksize=self.BLOCKSIZE, callback=callback)
    with stream:
        while True:
            indata, status = await q_in.get()
            yield indata, status</code></pre>
</details>
</dd>
<dt id="pysistent.InputStreamGenerator.InputStreamGenerator.set_silence_threshold"><code class="name flex">
<span>async def <span class="ident">set_silence_threshold</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Automatically sets the silence threshold for the input stream based on the first few seconds of audio data.</p>
<p>This method processes incoming audio data from the input stream, computes the average loudness over the first few seconds, and sets the <code>SILENCE_THRESHOLD</code> attribute based on the computed average loudness and the <code>SILENCE_RATIO</code> parameter.</p>
<p>The method continues processing audio data until the <code>ADJUSTMENT_TIME</code> duration has elapsed, at which point it sets the <code>SILENCE_THRESHOLD</code> and exits.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def set_silence_threshold(self):
    &#34;&#34;&#34;Automatically sets the silence threshold for the input stream based on the first few seconds of audio data.

    This method processes incoming audio data from the input stream, computes the average loudness over the first few seconds, and sets the `SILENCE_THRESHOLD` attribute based on the computed average loudness and the `SILENCE_RATIO` parameter.

    The method continues processing audio data until the `ADJUSTMENT_TIME` duration has elapsed, at which point it sets the `SILENCE_THRESHOLD` and exits.
    &#34;&#34;&#34;
    blocks_processed: int = 0
    loudness_values: list = []

    async for indata, _ in self.generate():
        blocks_processed += 1
        indata_flattened: np.ndarray = abs(indata.flatten())

        # Compute loudness over first few seconds to adjust silence threshold
        loudness_values.append(np.mean(indata_flattened))

        # Stop recording after ADJUSTMENT_TIME seconds
        if blocks_processed &gt;= self.ADJUSTMENT_TIME * self.SAMPLERATE / self.BLOCKSIZE:
            self.SILENCE_THRESHOLD = int((np.mean(loudness_values) * self.SILENCE_RATIO) / 15)
            break
        
    print(f&#39;\nSet SILENCE_THRESHOLD to {self.SILENCE_THRESHOLD}\n&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pysistent" href="index.html">pysistent</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pysistent.InputStreamGenerator.InputStreamGenerator" href="#pysistent.InputStreamGenerator.InputStreamGenerator">InputStreamGenerator</a></code></h4>
<ul class="">
<li><code><a title="pysistent.InputStreamGenerator.InputStreamGenerator.generate" href="#pysistent.InputStreamGenerator.InputStreamGenerator.generate">generate</a></code></li>
<li><code><a title="pysistent.InputStreamGenerator.InputStreamGenerator.set_silence_threshold" href="#pysistent.InputStreamGenerator.InputStreamGenerator.set_silence_threshold">set_silence_threshold</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>